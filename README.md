# Table of Contents
1. Introduction
2. Projects

   2.1. Realtime Face Beautification
   
   2.2. Hair Recolor
   
   2.3. Synthetic Face Generation and Editing using StyleGAN3 and InterFaceGAN
   
   2.4. Room Remodelling using Stable Diffusion
   
   2.5. Removing Captions from Videos/GIFS

   2.6. People Counting and Segmentation

   2.7. Crowd Proximity Detection

   2.8. Human Body Part Segmentation

   2.9. Custom Object Detection using YOLOv8

   2.10. Realtime Object Detection on Android/iOS
3. Contact

# 1. Introduction
Meet Muhammad Abdullah, a passionate engineer with interest in mathematics, computer science and problem-solving. With his newfound knowledge and skillset in the field of AI and machine learning, he's looking towards solving real-world problems and helping businesses boost their productivity.
# 2. Projects
## 2.1. Realtime Face Beautification
Not ready for that online interview!? No problem, this project is what you need!

Using Mediapipe in combination with OpenCV, this project smartly applies facial filters to remove spots and apply lipstick, etc. while maintaining real and authentic look. The model is lightweight so it can give around 30FPS on CPU. The next phase of the project would be a mobile version of this project with more added features.

https://github.com/baig97/baig97/assets/88559985/17acf8ba-6773-42bd-90ce-3889985d7cc3

https://github.com/baig97/baig97/assets/88559985/cc7349f6-5184-4945-823a-87a0a6988583

https://github.com/baig97/baig97/assets/88559985/ff3e0cb2-ddd7-44d4-981f-ce5aa827976e

## 2.2. Hair Recolor
Using semantic segmentation and custom computer vision algorithms, this project can recolor your hair to any shade you desire.

<figure style="text-align:center">
    <table>
    <tr>
        <td>
        <img src="Hair Recolor/color_1_1.png" alt="Hair recoloring to chestnut brown" width="400">
        </td>
        <td>
        <img src="Hair Recolor/color_1_2.png" alt="Hair recoloring to chestnut brown" width="400">
        </td>
    </tr>
    <tr>
        <td>
        <img src="Hair Recolor/color_1_3.png" alt="Hair recoloring to chestnut brown" width="400">
        </td>
        <td>
        <img src="Hair Recolor/color_1_4.png" alt="Hair recoloring to chestnut brown" width="400">
        </td>
    </tr>
    </table>
    <figcaption style="text-align: center"><em>Figure 2.2.1: Hair recoloring to chestnut brown</em></figcaption>
</figure>

## 2.3. Synthetic Face Generation and Editing using StyleGAN3 and InterFaceGAN
First, a few images of synthetic faces are generated by StyleGAN3.
<figure style="text-align: center">
    <img src="FaceGen + Remodel/genrated_images_using_stylegan3.jpeg" alt="Synthetic AI Generated Images" width="800">
    <figcaption style="text-align: center"><em>Figure 2.3.1: Synthetic faces generated using stylegan3</em></figcaption>
</figure>

Then, these latent codes of these images are editing using InterFaceGAN directions to achieve desired effect. Real images can also be easily edited using various GAN techniques using e4e or pSp encoder. Have a look at some of the edits made using InterFaceGAN:
<figure style="text-align: center">
    <img src="FaceGen + Remodel/attractive_filter_using_interfacegan.jpeg" alt="Attractive filter" width="800">
    <figcaption style="text-align: center"><em>Figure 2.3.2: Attractive filter</em></figcaption>
</figure>
<figure style="text-align: center">
    <img src="FaceGen + Remodel/feminine_filter_using_interfacegan.jpeg" alt="Feminine filter" width="800">
    <figcaption style="text-align: center"><em>Figure 2.3.3: Feminine filter</em></figcaption>
</figure>
<figure style="text-align: center">
    <img src="FaceGen + Remodel/smile_filter_using_interfacegan.jpeg" alt="Smile filter" width="800">
    <figcaption style="text-align: center"><em>Figure 2.3.4: Smile filter</em></figcaption>
</figure>
<figure style="text-align: center">
    <img src="FaceGen + Remodel/gen1_blackhair.jpeg" alt="Black hair filter" width="800">
    <figcaption style="text-align: center"><em>Figure 2.3.5: Black hair filter</em></figcaption>
</figure>
<figure style="text-align: center">
    <img src="FaceGen + Remodel/gen1_smile_attractive.jpeg" alt="Smile + Attractive filter" width="800">
    <figcaption style="text-align: center"><em>Figure 2.3.6: Smile + Attractive filter</em></figcaption>
</figure>

## 2.4. Room Remodelling using Stable Diffusion
An input image of a room is fed to Stable Diffusion model.
<figure style="text-align: center">
    <img src="Room Remodeling using Stable Diffusion v2.1/input_living_room.jpg" alt="Picture of an old fashioned living room" width="800">
    <figcaption style="text-align: center"><em>Figure 2.4.1: Input image to be remodelled</em></figcaption>
</figure>

### Using depth2img for equi-depth output
Using depth2img from Stable Diffusion 2.1, the room is remodelled using a given prompt. The benefit of using depth2img is that the remodelled version of the room retains the walls and objects in the correct places. However, it might be undesirable when only partial remodelling is required (like changing furniture etc.)

Below are the results from two different prompts using depth2img.
<figure style="text-align: center">
    <table>
        <tr>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/equal_depth/equal_depth_medieval_1.png" alt="Medieval style image output" width="400">
            </td>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/equal_depth/equal_depth_medieval_2.png" alt="Medieval style image output" width="400">
            </td>
        </tr>
        <tr>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/equal_depth/equal_depth_medieval_3.png" alt="Medieval style image output" width="400">
            </td>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/equal_depth/equal_depth_medieval_4.png" alt="Medieval style image output" width="400">
            </td>
        </tr>
    </table>
    <figcaption style="text-align: center"><em>Figure 2.4.2: Equi-depth outputs with prompt "minimalistic medieval bedroom"</em></figcaption>
</figure>
<figure style="text-align: center">
    <table>
        <tr>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/equal_depth/equal_depth_modern_1.png" alt="Modern style image output" width="400">
            </td>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/equal_depth/equal_depth_modern_2.png" alt="Modern style image output" width="400">
            </td>
        </tr>
        <tr>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/equal_depth/equal_depth_modern_3.png" alt="Modern style image output" width="400">
            </td>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/equal_depth/equal_depth_modern_4.png" alt="Modern style image output" width="400">
            </td>
        </tr>
    </table>
    <figcaption style="text-align: center"><em>Figure 2.4.3: Equi-depth outputs with prompt "minimalistic modern bedroom"</em></figcaption>
</figure>

### Using image inpainting with manual selection
When partial remodelling like furniture change is required, selective inpainting gives better results as demonstrated in this section. Below is the manual selection on the image (shown in black).
<figure style="text-align: center">
    <img src="Room Remodeling using Stable Diffusion v2.1/manual_selection/manual_selection.png" alt="Manual selection applied on input image" width="600">
    <figcaption style="text-align: center"><em>Figure 2.4.4: Manual selection applied on input image</em></figcaption>
</figure>
Again, the results with the same two prompts are shown.
<figure style="text-align: center">
    <table>
        <tr>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/manual_selection/manual_selection_medieval_1.png" alt="Medieval style image output" width="400">
            </td>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/manual_selection/manual_selection_medieval_2.png" alt="Medieval style image output" width="400">
            </td>
        </tr>
        <tr>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/manual_selection/manual_selection_medieval_3.png" alt="Medieval style image output" width="400">
            </td>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/manual_selection/manual_selection_medieval_4.png" alt="Medieval style image output" width="400">
            </td>
        </tr>
    </table>
    <figcaption style="text-align: center"><em>Figure 2.4.5: Manual selection with inpainting outputs with prompt "minimalistic medieval bedroom"</em></figcaption>
</figure>
<figure style="text-align: center">
    <table>
        <tr>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/manual_selection/manual_selection_modern_1.png" alt="Modern style image output" width="400">
            </td>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/manual_selection/manual_selection_modern_2.png" alt="Modern style image output" width="400">
            </td>
        </tr>
        <tr>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/manual_selection/manual_selection_modern_3.png" alt="Modern style image output" width="400">
            </td>
            <td>
                <img src="Room Remodeling using Stable Diffusion v2.1/manual_selection/manual_selection_modern_4.png" alt="Modern style image output" width="400">
            </td>
        </tr>
    </table>
    <figcaption style="text-align: center"><em>Figure 2.4.6: Manual selection with inpainting outputs with prompt "minimalistic modern bedroom"</em></figcaption>
</figure>

The results show that selective inpainting can lead to better results when only partial remodelling is required. This is just a proof of concept. The current project can be upgraded to automatically detect and inpaint certain objects in the scene.

## 2.5. Removing Captions from Videos/GIFS
The project comes in form of a script which can take in a video/GIF as input and remove text overlay from it and inpaint the video in that region to generate a seamless output video/GIF.

Below are some sample input GIFs:
<figure style="text-align: center">
    <table>
        <tr>
            <td>
                <img src="Removing Captions from Videos/inputs/1.gif" alt="Sample GIF with caption" width="400">
            </td>
            <td>
                <img src="Removing Captions from Videos/inputs/2.gif" alt="Sample GIF with caption" width="400">
            </td>
        </tr>
        <tr>
            <td>
                <img src="Removing Captions from Videos/inputs/3.gif" alt="Sample GIF with caption" width="400">
            </td>
            <td>
                <img src="Removing Captions from Videos/inputs/4.gif" alt="Sample GIF with caption" width="400">
            </td>
        </tr>
    </table>
    <figcaption style="text-align: center"><em>Figure 2.5.1: Input GIFs with captions</em></figcaption>
</figure>

And these are the output GIFs generated after caption removal and inpainting:
<figure style="text-align: center">
    <table>
        <tr>
            <td>
                <img src="Removing Captions from Videos/results/1.gif" alt="Sample GIF with caption" width="400">
            </td>
            <td>
                <img src="Removing Captions from Videos/results/2.gif" alt="Sample GIF with caption" width="400">
            </td>
        </tr>
        <tr>
            <td>
                <img src="Removing Captions from Videos/results/3.gif" alt="Sample GIF with caption" width="400">
            </td>
            <td>
                <img src="Removing Captions from Videos/results/4.gif" alt="Sample GIF with caption" width="400">
            </td>
        </tr>
    </table>
    <figcaption style="text-align: center"><em>Figure 2.5.2: Output GIFs without captions</em></figcaption>
</figure>

## 2.6. People Counting and Segmentation
This is demonstration of a simple but common application of realtime object detection.
<figure style="text-align:center">
    <img src="Object Detection and Segmentation/Using Pretrained Models/people_det.jpg" alt="Detecting people in a crowd" width="800">
    <figcaption style="text-align: center"><em>Figure 2.6.1: People counting</em></figcaption>
</figure>
<figure style="text-align:center">
    <img src="Object Detection and Segmentation/Using Pretrained Models/people_seg.jpg" alt="Segmenting people in a crowd" width="800">
    <figcaption style="text-align: center"><em>Figure 2.6.2: People segmentation</em></figcaption>
</figure>

## 2.7. Crowd Proximity Detection
The people counting application is enhanced via object promixity detection which works applying DPT by Intel on the image and combining the results with object detection output.

The image on the left shows a number over each box showing distance on an arbitary scale to the object. The image on the right shows the heatmap.
<figure style="text-align: center">
    <table>
    <tr>
        <td>
        <img src="Object Detection and Segmentation/Using Pretrained Models/crowd_detection_with_depth.png" alt="Crowd Detection with Proximity Sensing" width="400">
        </td>
        <td>
        <img src="Object Detection and Segmentation/Using Pretrained Models/crowd_depth_heat_map.png" alt="Crowd proximity heatmap" width="400">
        </td>
    </tr>
    </table>
    <figcaption style="text-align: center"><em>Figure 2.7.1: Crowd proximity detection with heatmap</em></figcaption>
</figure>

The application can be used in assistive equipment for the visually impaired people.

## 2.8. Human Body Part Segmentation
This is a demonstration project that uses semantic segmentation to segment human body parts.
<figure style="text-align: center">
    <table>
        <tr>
            <td>
                <img src="Object Detection and Segmentation/Using Pretrained Models/man_seg_1.jpg" alt="Human Body Part Segmentation" width="400">
            </td>
            <td>
                <img src="Object Detection and Segmentation/Using Pretrained Models/man_seg_2.jpg" alt="Human Body Part Segmentation" width="400">
            </td>
        </tr>
    </table>
    <figcaption style="text-align: center"><em>Figure 2.8.1: Human Body Part Segmentation</em></figcaption>
</figure>

## 2.9. Custom Object Detection using YOLOv8
This project demonstrates custom object detection via transfer learning using YOLOv8. Using transfer learning, YOLOv8 is trained on a moderate-sized dataset to detect potholes. The trained model gives great results.
<figure style="text-align: center">
    <img src="Object Detection and Segmentation/Custom Training/test_batch0_labels.jpg" alt="Test ground-truth labels" width="600">
    <figcaption style="text-align: center"><em>Figure 2.9.1: Test ground truth boxes</em></figcaption>
</figure>

<figure style="text-align: center">
    <img src="Object Detection and Segmentation/Custom Training/test_batch0_pred.jpg" alt="Test predictions" width="600">
    <figcaption style="text-align: center"><em>Figure 2.9.2: Test predicted boxes</em></figcaption>
</figure>

## 2.10. Realtime Object Detection on Android/iOS
This project takes any trained YOLO model and embeds it in a simple mobile application to perform realtime object detection from mobile devices.
<figure style="text-align: center">
    <table>
        <tr>
            <td>
                <img src="Object Detection and Segmentation/Using Pretrained Models/object_detection_using_yolov5_result_1.jpg" alt="Object detection on mobile app" width="400">
            </td>
            <td>
                <img src="Object Detection and Segmentation/Using Pretrained Models/object_detection_using_yolov5_result_2.jpg" alt="Object detection on mobile app" width="400">
            </td>
        </tr>
    </table>
    <figcaption style="text-align: center"><em>Figure 2.10.1: Realtime object detection on Android</em></figcaption>
</figure>

# 3. Contact

If you want to discuss your ideas or projects with me, you can always connect with me on [LinkedIn](https://www.linkedin.com/in/muhammad-abdullah-baig-173132200/), [Upwork](https://www.upwork.com/freelancers/~019e0881ebf1f3feab), or [Fiverr](https://www.fiverr.com/mab_07).







